---
layout: post
title: 19. Tf-idf, AKA "Computing is too important to be left to men"
---

När man vill hitta dokument som matchar en viss söksträng, t.ex. "den stora älgvandringen", har man ofta nytta av något som kallas **tf-idf**: (*term-frequency-inverse document frequency*). Tf-idf är ett statistiskt mått på ett ords frekvens sett till dess förekomst i hela dokumentsamlingen, vilket är mer effektivt än att bara se till dess frekvens i varje enskilt dokument. Det löser problemet med att dokument kan variera i längd och att vissa ord är mer vanligt förekommande än andra, som "den" och "stora" i förhållande till "älgvandring". Tf-idf används även för att vikta betydelsen av närliggande ord när man skapar ordvektorer.   

**Tf** (*term frequency*) är den råa **ordfrekvensen**, alltså antalet gånger ett visst ord förekommer i ett dokument. Den siffran kan plattas till genom att istället använda log<sub>10</sub> av frekvensen ([Jurafsky & Martin 2019](https://web.stanford.edu/~jurafsky/slp3/6.pdf)). Log<sub>10</sub> av ordfrekvensen 1000 blir exempelvis 3 (eftersom 10<sup>3</sup> = 1000). För att hantera ord som inte förekommer alls i vissa dokument kan man addera 1 till räkningen. 

Den andra delen av måttet, **idf** (*inverse document frequency*), går ut på att räkna antalet dokument i en dokumentsamling som ett visst ord förekommer i (alltså *inte* antalet gånger det förekommer i hela samlingen, utan bara antalet dokument). Om ordet bara förekommer i några få dokument vill vi visa det på något sätt, eftersom "[t]erms that are limited to a few documents are useful for discriminating those documents from the rest of the collection; terms that occur frequently across the entire collection aren't as helpful" ([Jurafsky & Martin 2019:6:13](https://web.stanford.edu/~jurafsky/slp3/6.pdf)). 

Det är här i:et i idf kommer in i bilden. *Inverse document frequency* ("omkastad dokumentfrekvens"?) innebär att man tar den totala mängden dokument (N) och delar den med dokumentfrekvensen för ett givet ord (N/df). Ju färre dokument ett ord förekommer i, desto större vikt får det ordet. Även idf-värdet kan loggas till 10 och multipliceras sedan med ordfrekvensen tf för att få det slutgiltiga tf-idf-värdet. Forskaren som föreslog det här sättet att vikta ord på i en artikel publicerad 1972, och därigenom la grunden för dagens sökmotorer, var [Karen Spärck Jones (1935-2007)](https://en.wikipedia.org/wiki/Karen_Sp%C3%A4rck_Jones).

<p align="center">
<img src="/images/sparck_jones.jpg" alt="Karen Spärck Jones" border="10" /><br>University of Cambridge / CC BY (https://creativecommons.org/licenses/by/2.5)
</p> 

Hon var en brittisk språkteknolog som förutom att vinna en massa utmärkelser för sin forskning (bl.a. första att kvinna att motta British Computer Societys (BCS) Lovelace Medal) också gjorde sig till en förespråkare för betydelsen av att locka fler kvinnor till datavetenskapen med mottot: *“Computing is too important to be left to men”*. New York Times har skrivit en fin minnesruna över henne som går att läsa [här](https://www.nytimes.com/2019/01/02/obituaries/karen-sparck-jones-overlooked.html), och den [här](https://www.bcs.org/content-hub/computings-too-important-to-be-left-to-men/) intervjun med henne från BCS är också riktigt läsvärd. 